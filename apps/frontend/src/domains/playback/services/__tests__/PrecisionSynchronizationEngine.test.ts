/**
 * PrecisionSynchronizationEngine Test Suite
 *
 * Tests for Story 2.3 Task 4: Advanced Synchronization & Timing Engine
 *
 * Test Coverage:
 * - Subtask 4.1: Precision timing with microsecond-level accuracy
 * - Subtask 4.2: Advanced drift correction with predictive algorithms
 * - Subtask 4.3: Adaptive latency compensation with device calibration
 * - Subtask 4.4: Cross-component synchronization with visual elements
 * - Subtask 4.5: Synchronization health monitoring and automatic recovery
 */

import {
  describe,
  test,
  expect,
  beforeEach,
  afterEach,
  vi,
  beforeAll,
} from 'vitest';
import {
  PrecisionSynchronizationEngine,
  DriftMeasurement,
  DeviceProfile,
  SyncHealthMetrics,
  VisualSyncComponent,
  MusicalTiming,
} from '../PrecisionSynchronizationEngine.js';

// Mock Tone.js
vi.mock('tone', () => {
  const createMockAudioParam = (defaultValue = 0) => ({
    value: defaultValue,
    defaultValue,
    maxValue: 1000,
    minValue: -1000,
    units: 'generic',
    setValueAtTime: vi.fn(),
    linearRampToValueAtTime: vi.fn(),
    exponentialRampToValueAtTime: vi.fn(),
    setTargetAtTime: vi.fn(),
    setValueCurveAtTime: vi.fn(),
    cancelScheduledValues: vi.fn(),
    cancelAndHoldAtTime: vi.fn(),
  });

  return {
    Transport: {
      bpm: createMockAudioParam(120),
      seconds: 0,
      start: vi.fn(),
      pause: vi.fn(),
      stop: vi.fn(),
      scheduleRepeat: vi.fn(),
      cancel: vi.fn(),
    },
    getContext: vi.fn(() => ({
      state: 'running',
      sampleRate: 44100,
      currentTime: 0,
      lookAhead: 0.1,
      updateInterval: 0.025,
    })),
    setContext: vi.fn(),
    now: vi.fn(() => 0),
  };
});

// Mock controllers
vi.mock('../ProfessionalPlaybackController.js', () => ({
  ProfessionalPlaybackController: {
    getInstance: vi.fn(() => ({
      play: vi.fn(),
      pause: vi.fn(),
      stop: vi.fn(),
      on: vi.fn(),
      off: vi.fn(),
      getState: vi.fn(() => 'stopped'),
    })),
  },
}));

vi.mock('../IntelligentTempoController.js', () => ({
  IntelligentTempoController: {
    getInstance: vi.fn(() => ({
      setTempo: vi.fn(),
      getTempo: vi.fn(() => 120),
      on: vi.fn(),
      off: vi.fn(),
    })),
  },
}));

vi.mock('../TranspositionController.js', () => ({
  TranspositionController: {
    getInstance: vi.fn(() => ({
      transpose: vi.fn(),
      getCurrentTransposition: vi.fn(() => 0),
      on: vi.fn(),
      off: vi.fn(),
    })),
  },
}));

describe('PrecisionSynchronizationEngine', () => {
  let syncEngine: PrecisionSynchronizationEngine;
  let mockAudioContext: AudioContext;

  beforeAll(() => {
    // Mock AudioContext with proper Web Audio API nodes
    global.AudioContext = vi.fn(() => ({
      currentTime: 0,
      sampleRate: 44100,
      state: 'running',
      createOscillator: vi.fn(() => ({
        connect: vi.fn(),
        start: vi.fn(),
        stop: vi.fn(),
        frequency: { value: 440 },
        type: 'sine',
        disconnect: vi.fn(),
      })),
      createAnalyser: vi.fn(() => ({
        connect: vi.fn(),
        disconnect: vi.fn(),
        frequencyBinCount: 1024,
        getByteFrequencyData: vi.fn(),
        fftSize: 2048,
      })),
      createGain: vi.fn(() => ({
        connect: vi.fn(),
        disconnect: vi.fn(),
        gain: { value: 1 },
      })),
      destination: {
        connect: vi.fn(),
        disconnect: vi.fn(),
      },
    })) as any;

    // Mock navigator for device detection tests
    global.navigator = {
      userAgent:
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
      platform: 'MacIntel',
    } as any;

    global.OscillatorNode = vi.fn() as any;
    global.AnalyserNode = vi.fn() as any;
    global.performance = {
      now: vi.fn(() => Date.now()),
      timeOrigin: Date.now(),
    } as any;
    global.requestAnimationFrame = vi.fn((callback) =>
      setTimeout(callback, 16),
    ) as any;

    console.log('ðŸ§ª Test setup: Global mocks initialized');
  });

  beforeEach(() => {
    // Reset all mocks
    vi.clearAllMocks();

    // Mock AudioContext
    mockAudioContext = {
      currentTime: 1.0,
      sampleRate: 44100,
      state: 'running',
      createGain: vi.fn().mockReturnValue({
        connect: vi.fn(),
        disconnect: vi.fn(),
        gain: { value: 1 },
      }),
      createOscillator: vi.fn().mockReturnValue({
        connect: vi.fn(),
        disconnect: vi.fn(),
        start: vi.fn(),
        stop: vi.fn(),
        frequency: { value: 440 },
      }),
      destination: {},
    } as unknown as AudioContext;

    // Enhanced Tone.js Transport mock with all required methods
    const mockTransport = {
      seconds: 2.0, // Set to 2.0 for musical position test
      bpm: { value: 120 },
      start: vi.fn(),
      stop: vi.fn(),
      pause: vi.fn(),
      position: '0:0:0',
      state: 'stopped',
    };

    // Mock Tone.js module
    vi.doMock('tone', () => ({
      Transport: mockTransport,
      context: {
        currentTime: 1.0,
      },
    }));

    // Store the mock transport for later use in tests
    (global as any).mockToneTransport = mockTransport;

    // Mock navigator for device detection
    Object.defineProperty(global, 'navigator', {
      value: {
        userAgent: 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)',
        platform: 'MacIntel',
      },
      writable: true,
    });

    // Reset singleton instance for testing
    (PrecisionSynchronizationEngine as any).instance = null;

    // Create fresh engine instance using singleton pattern
    syncEngine = PrecisionSynchronizationEngine.getInstance();

    // Mock the current time to be predictable
    vi.spyOn(mockAudioContext, 'currentTime', 'get').mockReturnValue(1.234567);

    // Mock the calibration method to resolve immediately
    const mockCalibration = vi.fn().mockResolvedValue({
      deviceType: 'desktop',
      audioLatency: 50,
      visualLatency: 16,
      systemLatency: 10,
      recommendedBufferSize: 256,
      compensationOffset: 5,
      calibrationAccuracy: 95,
      lastCalibration: Date.now(),
    });

    // Mock the latency compensator before initialization
    vi.spyOn(syncEngine as any, 'performInitialCalibration').mockImplementation(
      async () => {
        console.log('ðŸ§ª Mock: performInitialCalibration called');
        // Simulate quick calibration
        await new Promise((resolve) => setTimeout(resolve, 10));
        console.log('ðŸ§ª Mock: performInitialCalibration completed');
      },
    );

    // Also mock the latencyCompensator.calibrateForDevice method
    const originalInit = syncEngine.initialize.bind(syncEngine);
    vi.spyOn(syncEngine, 'initialize').mockImplementation(
      async (audioContext) => {
        console.log('ðŸ§ª Mock: initialize called');

        // Call original but with mocked calibration
        const result = await originalInit(audioContext);

        // Ensure latency compensator is mocked after initialization
        const latencyCompensator = (syncEngine as any).latencyCompensator;
        if (latencyCompensator && latencyCompensator.calibrateForDevice) {
          vi.spyOn(latencyCompensator, 'calibrateForDevice').mockImplementation(
            mockCalibration,
          );
        }

        console.log('ðŸ§ª Mock: initialize completed');
        return result;
      },
    );
  });

  afterEach(() => {
    syncEngine.dispose();
    vi.clearAllMocks();
  });

  // ============================================================================
  // SUBTASK 4.1: PRECISION TIMING WITH MICROSECOND-LEVEL ACCURACY
  // ============================================================================

  describe('Subtask 4.1: Precision Timing with Microsecond-Level Accuracy', () => {
    test('should initialize with microsecond precision timing', async () => {
      await syncEngine.initialize(mockAudioContext);

      expect(syncEngine).toBeDefined();
      expect(typeof syncEngine.getCurrentMusicalPosition).toBe('function');
    });

    test('should provide microsecond-level timing accuracy', async () => {
      await syncEngine.initialize(mockAudioContext);

      const position = syncEngine.getCurrentMusicalPosition();

      if (position) {
        expect(position.syncAccuracy).toBeGreaterThan(90); // >90% accuracy
        expect(position.audioTime).toBeCloseTo(mockAudioContext.currentTime, 6); // 6 decimal places = microsecond
        expect(typeof position.musicalTime).toBe('number');
        expect(typeof position.bars).toBe('number');
        expect(typeof position.beats).toBe('number');
        expect(typeof position.subdivisions).toBe('number');
      }
    });

    test('should calculate musical position with precise timing', async () => {
      await syncEngine.initialize(mockAudioContext);

      // Manually set the transport time for this test
      const engine = syncEngine as any;
      if (engine.toneTransport) {
        engine.toneTransport.seconds = 2.0; // Set to 2 seconds for the test
        console.log('ðŸ§ª TEST: Set transport.seconds to 2.0');
      }

      const position = syncEngine.getCurrentMusicalPosition();

      expect(position).toBeDefined();
      if (position) {
        // At 120 BPM: 2 beats per second, so 2 seconds = 4 total beats
        // In 4/4 time: 4 beats = 1 complete bar (bars=1) + 0 beats in current bar (beats=0)
        expect(position.totalBeats).toBe(4); // 2 seconds at 120 BPM = 4 total beats
        expect(position.bars).toBe(1); // 4 total beats = 1 complete bar in 4/4 time
        expect(position.beats).toBe(0); // 0 beats in current bar (start of bar 2)
        expect(position.timeSignature.numerator).toBe(4);
        expect(position.timeSignature.denominator).toBe(4);
      }
    });

    test('should provide next sync point with microsecond precision', async () => {
      await syncEngine.initialize(mockAudioContext);

      const syncPoint = syncEngine.getNextSyncPoint();

      expect(syncPoint).toBeGreaterThan(mockAudioContext.currentTime);
      expect(syncPoint).toBeLessThan(mockAudioContext.currentTime + 1); // Within 1 second

      // Should be precise to microseconds (6 decimal places)
      const precision = syncPoint.toString().split('.')[1]?.length || 0;
      expect(precision).toBeGreaterThanOrEqual(3);
    }, 1000); // Reduce timeout to 1 second

    test('should maintain timing accuracy during playback', async () => {
      await syncEngine.initialize(mockAudioContext);

      const accuracyReadings: number[] = [];

      // Collect accuracy readings over time
      for (let i = 0; i < 5; i++) {
        const position = syncEngine.getCurrentMusicalPosition();
        if (position) {
          accuracyReadings.push(position.syncAccuracy);
        }
        await new Promise((resolve) => setTimeout(resolve, 10));
      }

      // All readings should maintain high accuracy
      accuracyReadings.forEach((accuracy) => {
        expect(accuracy).toBeGreaterThan(85); // Maintain >85% accuracy
      });
    });
  });

  // ============================================================================
  // SUBTASK 4.2: ADVANCED DRIFT CORRECTION WITH PREDICTIVE ALGORITHMS
  // ============================================================================

  describe('Subtask 4.2: Advanced Drift Correction with Predictive Algorithms', () => {
    test('should detect and measure drift accurately', async () => {
      await syncEngine.initialize(mockAudioContext);

      const measurement = await new Promise<DriftMeasurement>((resolve) => {
        syncEngine.once('drift_measured', resolve);
        syncEngine.correctDrift('audio', 1.0, 1.00005); // 50 microseconds drift
      });

      expect(measurement.drift).toBeCloseTo(50, 1); // 50 microseconds
      expect(measurement.severity).toBe('medium'); // 50Î¼s = medium severity (50-99Î¼s range)
      expect(measurement.source).toBe('audio');
      expect(typeof measurement.predictedCorrection).toBe('number');
    });

    test('should classify drift severity correctly', async () => {
      await syncEngine.initialize(mockAudioContext);

      const testCases = [
        { drift: 5, severity: 'low' }, // < 10 microseconds
        { drift: 50, severity: 'medium' }, // < 100 microseconds
        { drift: 500, severity: 'high' }, // < 1000 microseconds
        { drift: 2000, severity: 'critical' }, // >= 1000 microseconds
      ];

      for (const testCase of testCases) {
        const expectedTime = 1.0;
        const actualTime = expectedTime + testCase.drift / 1000000;

        const measurementPromise = new Promise<DriftMeasurement>((resolve) => {
          syncEngine.once('drift_measured', (measurement) => {
            resolve(measurement);
          });
        });

        syncEngine.correctDrift('test', expectedTime, actualTime);

        const measurement = await measurementPromise;
        expect(measurement.severity).toBe(testCase.severity);
      }
    });

    test('should provide predictive correction based on historical data', async () => {
      await syncEngine.initialize(mockAudioContext);

      // Create drift history pattern
      const driftHistory = [10, 12, 15, 18, 20]; // Increasing drift pattern

      for (let i = 0; i < driftHistory.length; i++) {
        const expectedTime = 1.0;
        const actualTime = expectedTime + driftHistory[i]! / 1000000;

        syncEngine.correctDrift('predictive_test', expectedTime, actualTime);
        await new Promise((resolve) => setTimeout(resolve, 10));
      }

      // Next correction should predict higher drift
      const finalExpectedTime = 1.0;
      const finalActualTime = finalExpectedTime + 25 / 1000000; // 25 microseconds

      const predictionPromise = new Promise<DriftMeasurement>((resolve) => {
        syncEngine.once('drift_corrected', ({ measurement }) => {
          resolve(measurement);
        });
      });

      syncEngine.correctDrift(
        'predictive_test',
        finalExpectedTime,
        finalActualTime,
      );

      const prediction = await predictionPromise;
      expect(prediction.predictedCorrection).toBeGreaterThan(20); // Should predict higher correction
    });

    test('should apply adaptive correction based on drift trends', async () => {
      await syncEngine.initialize(mockAudioContext);

      let correctionCount = 0;
      let totalCorrection = 0;

      syncEngine.on('drift_corrected', ({ correction }) => {
        correctionCount++;
        totalCorrection += Math.abs(correction);
      });

      // Simulate consistent drift pattern
      for (let i = 0; i < 10; i++) {
        const expectedTime = 1.0;
        const actualTime = expectedTime + (i * 10) / 1000000; // Increasing drift

        syncEngine.correctDrift('adaptive_test', expectedTime, actualTime);
        await new Promise((resolve) => setTimeout(resolve, 5));
      }

      expect(correctionCount).toBeGreaterThan(5); // Should have applied corrections
      expect(totalCorrection / correctionCount).toBeGreaterThan(0); // Average correction > 0
    });

    test('should ignore corrections below threshold', async () => {
      await syncEngine.initialize(mockAudioContext);

      let correctionApplied = false;

      syncEngine.once('drift_corrected', () => {
        correctionApplied = true;
      });

      // Drift below 10 microsecond threshold
      const expectedTime = 1.0;
      const actualTime = expectedTime + 5 / 1000000; // 5 microseconds

      syncEngine.correctDrift('threshold_test', expectedTime, actualTime);

      // Wait to ensure no correction event
      await new Promise((resolve) => setTimeout(resolve, 50));

      expect(correctionApplied).toBe(false);
    });
  });

  // ============================================================================
  // SUBTASK 4.3: ADAPTIVE LATENCY COMPENSATION WITH DEVICE CALIBRATION
  // ============================================================================

  describe('Subtask 4.3: Adaptive Latency Compensation with Device Calibration', () => {
    test('should perform device calibration', async () => {
      await syncEngine.initialize(mockAudioContext);

      // Mock latency compensator
      const mockCalibrate = vi.fn().mockResolvedValue({
        deviceType: 'desktop',
        audioLatency: 15000, // 15ms in microseconds
        visualLatency: 18000, // 18ms in microseconds
        systemLatency: 12000, // 12ms in microseconds
        recommendedBufferSize: 256,
        compensationOffset: 7500, // 7.5ms in microseconds
        calibrationAccuracy: 92,
        lastCalibration: Date.now(),
      } as DeviceProfile);

      // Access private latencyCompensator for testing
      const engine = syncEngine as any;
      if (engine.latencyCompensator) {
        engine.latencyCompensator.calibrateForDevice = mockCalibrate;

        const profile = await engine.latencyCompensator.calibrateForDevice();

        expect(profile.deviceType).toBe('desktop');
        expect(profile.audioLatency).toBe(15000);
        expect(profile.calibrationAccuracy).toBeGreaterThan(90);
        expect(typeof profile.lastCalibration).toBe('number');
      }
    });

    test('should detect device type correctly', async () => {
      await syncEngine.initialize(mockAudioContext);

      // Mock different user agents
      const originalUserAgent = navigator.userAgent;

      const testCases = [
        {
          userAgent: 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X)',
          expected: 'mobile',
        },
        {
          userAgent: 'Mozilla/5.0 (iPad; CPU OS 14_0 like Mac OS X)',
          expected: 'tablet',
        },
        {
          userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',
          expected: 'desktop',
        },
      ];

      for (const testCase of testCases) {
        Object.defineProperty(navigator, 'userAgent', {
          value: testCase.userAgent,
          configurable: true,
        });

        // Test device detection through calibration
        const engine = syncEngine as any;
        if (engine.latencyCompensator) {
          const detectDeviceType =
            engine.latencyCompensator.detectDeviceType?.bind(
              engine.latencyCompensator,
            );
          if (detectDeviceType) {
            const deviceType = detectDeviceType();
            expect(deviceType).toBe(testCase.expected);
          }
        }
      }

      // Restore original user agent
      Object.defineProperty(navigator, 'userAgent', {
        value: originalUserAgent,
        configurable: true,
      });
    });

    test('should adapt compensation based on system load', async () => {
      await syncEngine.initialize(mockAudioContext);

      const engine = syncEngine as any;
      if (engine.latencyCompensator) {
        // Mock device profile
        engine.latencyCompensator.deviceProfile = {
          compensationOffset: 10000, // 10ms base offset
        };

        const adaptToSystemLoad =
          engine.latencyCompensator.adaptToSystemLoad?.bind(
            engine.latencyCompensator,
          );
        if (adaptToSystemLoad) {
          // Test low load
          const lowLoadOffset = adaptToSystemLoad(10, 20); // 10% CPU, 20% memory
          expect(lowLoadOffset).toBeCloseTo(10300, 100); // Should be close to base + 3%

          // Test high load
          const highLoadOffset = adaptToSystemLoad(80, 70); // 80% CPU, 70% memory
          expect(highLoadOffset).toBeGreaterThan(11000); // Should increase compensation
        }
      }
    });

    test('should calculate optimal buffer size based on latency', async () => {
      await syncEngine.initialize(mockAudioContext);

      const engine = syncEngine as any;
      if (engine.latencyCompensator) {
        const calculateOptimalBufferSize =
          engine.latencyCompensator.calculateOptimalBufferSize?.bind(
            engine.latencyCompensator,
          );
        if (calculateOptimalBufferSize) {
          expect(calculateOptimalBufferSize(3000)).toBe(128); // < 5ms
          expect(calculateOptimalBufferSize(8000)).toBe(256); // < 10ms
          expect(calculateOptimalBufferSize(15000)).toBe(512); // < 20ms
          expect(calculateOptimalBufferSize(25000)).toBe(1024); // >= 20ms
        }
      }
    });

    test('should prevent concurrent calibration', async () => {
      await syncEngine.initialize(mockAudioContext);

      // Start first calibration
      const firstCalibration = syncEngine.calibrateForDevice();

      // Try to start second calibration while first is in progress
      await expect(syncEngine.calibrateForDevice()).rejects.toThrow(
        'Calibration already in progress',
      );

      // Wait for first calibration to complete
      await firstCalibration;
    });
  });

  // ============================================================================
  // SUBTASK 4.4: CROSS-COMPONENT SYNCHRONIZATION WITH VISUAL ELEMENTS
  // ============================================================================

  describe('Subtask 4.4: Cross-Component Synchronization with Visual Elements', () => {
    test('should register and manage visual components', async () => {
      await syncEngine.initialize(mockAudioContext);

      const mockComponent: VisualSyncComponent = {
        id: 'sheet-player-1',
        type: 'sheet-player',
        syncCallback: vi.fn(),
        latencyOffset: 5000,
        priority: 'high',
        isActive: true,
      };

      syncEngine.registerVisualComponent(mockComponent.id, mockComponent);

      const registeredComponent = syncEngine.getVisualComponent(
        mockComponent.id,
      );
      expect(registeredComponent).toEqual(mockComponent);
    });

    test('should unregister visual components', async () => {
      await syncEngine.initialize(mockAudioContext);

      const mockComponent: VisualSyncComponent = {
        id: 'fretboard-1',
        type: 'fretboard-visualizer',
        syncCallback: vi.fn(),
        latencyOffset: 3000,
        priority: 'medium',
        isActive: true,
      };

      // Register first
      syncEngine.registerVisualComponent(mockComponent.id, mockComponent);

      // Verify it's registered
      expect(syncEngine.getVisualComponent(mockComponent.id)).toEqual(
        mockComponent,
      );

      // Listen for unregistration event
      const unregisteredId = await new Promise<string>((resolve) => {
        syncEngine.once('component_unregistered', (data) => resolve(data.id));
        syncEngine.unregisterVisualComponent('fretboard-1');
      });

      expect(unregisteredId).toBe('fretboard-1');

      // Verify it's no longer registered
      expect(syncEngine.getVisualComponent('fretboard-1')).toBeNull();
    });

    test('should broadcast musical timing to visual components', async () => {
      await syncEngine.initialize(mockAudioContext);

      const mockCallback = vi.fn();
      const mockComponent: VisualSyncComponent = {
        id: 'test-visualizer',
        type: 'custom',
        syncCallback: mockCallback,
        latencyOffset: 2000, // 2ms offset
        priority: 'high',
        isActive: true,
      };

      syncEngine.registerVisualComponent(mockComponent.id, mockComponent);

      // Start synchronized playback to trigger timing broadcasts
      await syncEngine.startSynchronizedPlayback();

      // Wait for callback to be called
      await new Promise((resolve) => setTimeout(resolve, 100));

      expect(mockCallback).toHaveBeenCalled();

      if (mockCallback.mock.calls.length > 0) {
        const timing: MusicalTiming = mockCallback.mock.calls[0]?.[0];
        if (timing) {
          expect(timing.position).toBeDefined();
          expect(timing.tempo).toBeDefined();
          expect(timing.syncTimestamp).toBeDefined();
          expect(typeof timing.syncTimestamp).toBe('number');
        }
      }
    });

    test('should apply component-specific latency compensation', async () => {
      await syncEngine.initialize(mockAudioContext);

      const callbackTimes: number[] = [];
      const mockCallback = vi.fn((_timing: MusicalTiming) => {
        callbackTimes.push(performance.now());
      });

      const mockComponent: VisualSyncComponent = {
        id: 'latency-test',
        type: 'custom',
        syncCallback: mockCallback,
        latencyOffset: 10000, // 10ms offset
        priority: 'high',
        isActive: true,
      };

      syncEngine.registerVisualComponent(mockComponent.id, mockComponent);

      await syncEngine.startSynchronizedPlayback();

      // Wait for callback
      await new Promise((resolve) => setTimeout(resolve, 50));

      // Check that the callback was called with compensated timing
      expect(mockCallback).toHaveBeenCalled();

      if (mockCallback.mock.calls.length > 0) {
        const firstCall = mockCallback.mock.calls[0] as any[];
        if (firstCall && firstCall.length > 0) {
          const timing = firstCall[0] as MusicalTiming;

          // The syncTimestamp should be compensated by the latency offset
          // Original timestamp + 10000Î¼s latency offset
          expect(timing.syncTimestamp).toBeGreaterThan(0);

          // Check that latency compensation was applied (timestamp should be higher due to offset)
          const originalTimestamp = Date.now() * 1000; // Convert to microseconds
          const compensatedTimestamp = timing.syncTimestamp;
          const compensation = compensatedTimestamp - originalTimestamp;

          // Should have some compensation applied (allowing for timing variations)
          expect(Math.abs(compensation)).toBeGreaterThan(1000); // At least 1ms compensation
        }
      }
    });

    test('should prioritize high-priority components', async () => {
      await syncEngine.initialize(mockAudioContext);

      const highPriorityCallback = vi.fn();
      const lowPriorityCallback = vi.fn();

      const highPriorityComponent: VisualSyncComponent = {
        id: 'high-priority',
        type: 'sheet-player',
        syncCallback: highPriorityCallback,
        latencyOffset: 0,
        priority: 'high',
        isActive: true,
      };

      const lowPriorityComponent: VisualSyncComponent = {
        id: 'low-priority',
        type: 'custom',
        syncCallback: lowPriorityCallback,
        latencyOffset: 0,
        priority: 'low',
        isActive: true,
      };

      syncEngine.registerVisualComponent(
        highPriorityComponent.id,
        highPriorityComponent,
      );
      syncEngine.registerVisualComponent(
        lowPriorityComponent.id,
        lowPriorityComponent,
      );

      await syncEngine.startSynchronizedPlayback();

      // Wait for callbacks
      await new Promise((resolve) => setTimeout(resolve, 50));

      // Both should be called, but high priority should be called first
      // (This would be implementation-specific, here we just check both are called)
      expect(highPriorityCallback).toHaveBeenCalled();
      expect(lowPriorityCallback).toHaveBeenCalled();
    });

    test('should skip inactive visual components', async () => {
      await syncEngine.initialize(mockAudioContext);

      const activeCallback = vi.fn();
      const inactiveCallback = vi.fn();

      const activeComponent: VisualSyncComponent = {
        id: 'active',
        type: 'fretboard-visualizer',
        syncCallback: activeCallback,
        latencyOffset: 0,
        priority: 'high',
        isActive: true,
      };

      const inactiveComponent: VisualSyncComponent = {
        id: 'inactive',
        type: 'custom',
        syncCallback: inactiveCallback,
        latencyOffset: 0,
        priority: 'high',
        isActive: false,
      };

      syncEngine.registerVisualComponent(activeComponent.id, activeComponent);
      syncEngine.registerVisualComponent(
        inactiveComponent.id,
        inactiveComponent,
      );

      await syncEngine.startSynchronizedPlayback();

      // Wait for callbacks
      await new Promise((resolve) => setTimeout(resolve, 50));

      expect(activeCallback).toHaveBeenCalled();
      expect(inactiveCallback).not.toHaveBeenCalled();
    });
  });

  // ============================================================================
  // SUBTASK 4.5: SYNCHRONIZATION HEALTH MONITORING AND AUTOMATIC RECOVERY
  // ============================================================================

  describe('Subtask 4.5: Synchronization Health Monitoring and Automatic Recovery', () => {
    test('should provide comprehensive health metrics', async () => {
      await syncEngine.initialize(mockAudioContext);

      const healthMetrics = syncEngine.getHealthMetrics();

      expect(healthMetrics.overallHealth).toBeGreaterThanOrEqual(0);
      expect(healthMetrics.overallHealth).toBeLessThanOrEqual(100);
      expect(healthMetrics.audioSyncHealth).toBeGreaterThanOrEqual(0);
      expect(healthMetrics.audioSyncHealth).toBeLessThanOrEqual(100);
      expect(healthMetrics.visualSyncHealth).toBeGreaterThanOrEqual(0);
      expect(healthMetrics.visualSyncHealth).toBeLessThanOrEqual(100);
      expect(healthMetrics.driftLevel).toBeGreaterThanOrEqual(0);
      expect(healthMetrics.driftLevel).toBeLessThanOrEqual(100);
      expect(healthMetrics.latencyCompensation).toBeGreaterThanOrEqual(0);
      expect(healthMetrics.latencyCompensation).toBeLessThanOrEqual(100);
      expect(healthMetrics.performanceScore).toBeGreaterThanOrEqual(0);
      expect(healthMetrics.performanceScore).toBeLessThanOrEqual(100);
      expect(healthMetrics.recoveryAttempts).toBeGreaterThanOrEqual(0);
    });

    test('should emit health updates periodically', async () => {
      await syncEngine.initialize(mockAudioContext);

      let _healthUpdateCount = 0;
      let lastHealthMetrics: SyncHealthMetrics | null = null;

      syncEngine.on('health_updated', (metrics: SyncHealthMetrics) => {
        _healthUpdateCount++;
        lastHealthMetrics = metrics;
      });

      // Wait for health updates (should happen every 5 seconds in real implementation)
      // For testing, we'll trigger it manually or wait briefly
      await new Promise((resolve) => setTimeout(resolve, 100));

      // In real implementation, health updates would be periodic
      // For testing, we check the structure is correct
      expect(typeof syncEngine.getHealthMetrics).toBe('function');
      expect(lastHealthMetrics || syncEngine.getHealthMetrics()).toBeDefined();
    });

    test('should trigger recovery when health is poor', async () => {
      await syncEngine.initialize(mockAudioContext);

      let recoveryStarted = false;
      let recoveryAttempt = 0;

      syncEngine.on('recovery_complete', (data) => {
        recoveryStarted = true;
        recoveryAttempt = data.attempts;
      });

      // Simulate poor health condition
      syncEngine.triggerRecovery();

      // Wait for recovery to be triggered
      await new Promise((resolve) => setTimeout(resolve, 150));

      expect(recoveryStarted).toBe(true);
      expect(recoveryAttempt).toBeGreaterThan(0);
    });

    test('should complete recovery successfully', async () => {
      await syncEngine.initialize(mockAudioContext);

      let recoveryCompleted = false;
      let recoverySuccessful = false;

      syncEngine.on('recovery_complete', (data) => {
        recoveryCompleted = true;
        recoverySuccessful = data.success;
      });

      syncEngine.triggerRecovery();

      // Wait for recovery to complete
      await new Promise((resolve) => setTimeout(resolve, 150));

      expect(recoveryCompleted).toBe(true);
      expect(recoverySuccessful).toBe(true);
    });

    test('should limit recovery attempts', async () => {
      await syncEngine.initialize(mockAudioContext);

      let recoveryFailed = false;
      let failureData: any = null;

      syncEngine.on('recovery_failed', (data) => {
        console.log('ðŸ§ª TEST: recovery_failed event received:', data);
        recoveryFailed = true;
        failureData = data;
      });

      // Trigger multiple recovery attempts to exceed limit (max is 3)
      console.log('ðŸ§ª TEST: Starting recovery attempt sequence...');
      for (let i = 0; i < 5; i++) {
        console.log(`ðŸ§ª TEST: Triggering recovery attempt ${i + 1}`);
        syncEngine.triggerRecovery();
        await new Promise((resolve) => setTimeout(resolve, 120)); // Wait longer for recovery to complete
      }

      console.log(
        `ðŸ§ª TEST: Recovery failed: ${recoveryFailed}, Data:`,
        failureData,
      );
      expect(recoveryFailed).toBe(true);
    });

    test('should calculate audio sync health accurately', async () => {
      await syncEngine.initialize(mockAudioContext);

      const engine = syncEngine as any;
      if (engine.calculateAudioSyncHealth) {
        // Mock low drift
        engine.calculateCurrentDriftLevel = vi.fn().mockReturnValue(50); // 50 microseconds
        engine.config = { maxDriftTolerance: 100 }; // 100 microseconds max

        const health = engine.calculateAudioSyncHealth();
        expect(health).toBe(50); // 100 - (50/100)*100 = 50%

        // Mock no drift
        engine.calculateCurrentDriftLevel.mockReturnValue(0);
        const perfectHealth = engine.calculateAudioSyncHealth();
        expect(perfectHealth).toBe(100);
      }
    });

    test('should calculate visual sync health based on components', async () => {
      await syncEngine.initialize(mockAudioContext);

      // Register multiple visual components
      const component1: VisualSyncComponent = {
        id: 'visual-1',
        type: 'sheet-player',
        syncCallback: vi.fn(),
        latencyOffset: 0,
        priority: 'high',
        isActive: true,
      };

      const component2: VisualSyncComponent = {
        id: 'visual-2',
        type: 'fretboard-visualizer',
        syncCallback: vi.fn(),
        latencyOffset: 0,
        priority: 'medium',
        isActive: true,
      };

      syncEngine.registerVisualComponent(component1.id, component1);
      syncEngine.registerVisualComponent(component2.id, component2);

      const engine = syncEngine as any;
      if (engine.calculateVisualSyncHealth) {
        const visualHealth = engine.calculateVisualSyncHealth();
        expect(visualHealth).toBeGreaterThan(0);
        expect(visualHealth).toBeLessThanOrEqual(100);
      }
    });

    test('should track performance metrics over time', async () => {
      await syncEngine.initialize(mockAudioContext);

      const engine = syncEngine as any;
      if (engine.performanceMetrics) {
        const initialRecoveryAttempts =
          engine.performanceMetrics.recoveryAttempts;

        // Simulate performance update
        if (engine.updatePerformanceMetrics) {
          engine.updatePerformanceMetrics(1.234);
        }

        expect(engine.performanceMetrics.lastMeasurement).toBe(1.234);
        expect(engine.performanceMetrics.recoveryAttempts).toBe(
          initialRecoveryAttempts,
        );
      }
    });
  });

  // ============================================================================
  // INTEGRATION TESTS - TASK 4 COMPLETE SYSTEM
  // ============================================================================

  describe('Integration Tests - Complete Synchronization System', () => {
    test('should integrate all synchronization subsystems', async () => {
      await syncEngine.initialize(mockAudioContext);

      // Test that all subsystems are available
      expect(typeof syncEngine.getCurrentMusicalPosition).toBe('function'); // Precision timing
      expect(typeof syncEngine.correctDrift).toBe('function'); // Drift correction
      expect(typeof syncEngine.registerVisualComponent).toBe('function'); // Visual sync
      expect(typeof syncEngine.getHealthMetrics).toBe('function'); // Health monitoring

      // Test integrated workflow
      const component: VisualSyncComponent = {
        id: 'integration-test',
        type: 'sheet-player',
        syncCallback: vi.fn(),
        latencyOffset: 5000,
        priority: 'high',
        isActive: true,
      };

      syncEngine.registerVisualComponent(component.id, component);
      await syncEngine.startSynchronizedPlayback();

      // Simulate drift correction
      syncEngine.correctDrift('integration', 1.0, 1.000025);

      // Check health metrics
      const health = syncEngine.getHealthMetrics();
      expect(health.overallHealth).toBeGreaterThan(0);
    });

    test('should maintain synchronization under load', async () => {
      await syncEngine.initialize(mockAudioContext);

      // Register multiple visual components
      for (let i = 0; i < 10; i++) {
        const component: VisualSyncComponent = {
          id: `load-test-${i}`,
          type: 'custom',
          syncCallback: vi.fn(),
          latencyOffset: i * 1000, // Varying latency offsets
          priority: i % 2 === 0 ? 'high' : 'low',
          isActive: true,
        };
        syncEngine.registerVisualComponent(component.id, component);
      }

      await syncEngine.startSynchronizedPlayback();

      // Simulate multiple drift corrections
      for (let i = 0; i < 50; i++) {
        const expectedTime = 1.0;
        const actualTime = expectedTime + (Math.random() * 100) / 1000000;
        syncEngine.correctDrift(
          `load-test-${i % 10}`,
          expectedTime,
          actualTime,
        );
      }

      // System should remain stable
      const health = syncEngine.getHealthMetrics();
      expect(health.overallHealth).toBeGreaterThan(50); // Should maintain reasonable health

      const position = syncEngine.getCurrentMusicalPosition();
      expect(position).not.toBeNull(); // Should still provide position
    });

    test('should handle controller integration properly', async () => {
      await syncEngine.initialize(mockAudioContext);

      // Test event propagation from controllers
      let _playbackStateChanged = false;
      let _tempoChanged = false;
      let _transpositionChanged = false;

      syncEngine.on('playback_state_changed', () => {
        _playbackStateChanged = true;
      });

      syncEngine.on('tempo_changed', () => {
        _tempoChanged = true;
      });

      syncEngine.on('transposition_changed', () => {
        _transpositionChanged = true;
      });

      // Start playback to trigger controller integration
      await syncEngine.startSynchronizedPlayback();

      // The actual event triggering would depend on controller implementation
      // For this test, we verify the event handlers are set up
      expect(typeof syncEngine.listenerCount).toBe('function');
    });

    test('should provide comprehensive system status', async () => {
      await syncEngine.initialize(mockAudioContext);

      // Register component and start playback
      const component: VisualSyncComponent = {
        id: 'status-test',
        type: 'fretboard-visualizer',
        syncCallback: vi.fn(),
        latencyOffset: 3000,
        priority: 'medium',
        isActive: true,
      };

      syncEngine.registerVisualComponent(component.id, component);
      await syncEngine.startSynchronizedPlayback();

      // Get comprehensive status
      const position = syncEngine.getCurrentMusicalPosition();
      const health = syncEngine.getHealthMetrics();

      // Verify complete system state
      if (position) {
        expect(position.bars).toBeGreaterThanOrEqual(0);
        expect(position.beats).toBeGreaterThanOrEqual(0);
        expect(position.subdivisions).toBeGreaterThanOrEqual(0);
        expect(position.syncAccuracy).toBeGreaterThan(0);
      }

      expect(health.overallHealth).toBeGreaterThanOrEqual(0);
      expect(health.audioSyncHealth).toBeGreaterThanOrEqual(0);
      expect(health.visualSyncHealth).toBeGreaterThanOrEqual(0);
      expect(health.driftLevel).toBeGreaterThanOrEqual(0);
    });
  });
});
